
# A Chat with Andrew on MLOps: From Model-centric to Data-centric AI



[영상링크](https://www.youtube.com/watch?v=06-AZXmwHjo)

1. 데이터의 중요성

![캡처](.\acwa\캡처.PNG)

데이터 준비가 80%에 해당한다.

데이터 준비에 대해 체계적으로 이야기하는것 = mlops의 중요성

skim 해본 결과 abstract 중에 ~99%가 모델에 관한것이고, ~1%의 연구가 데이터 증강에 대한 것이었다.



2. ML project의 life cycle

   1) 프로젝트를 정의

   2) 데이터 수집

   3) 모델 트레이닝

   4) 데이터셋 개선 및 모델 개선

   5) 프로덕션 배포

   ![캡처2](.\acwa\캡처2.PNG)

3. 데이터의 퀄리티를 체계화하는 MLops : 라벨링된 데이터 간의 일관성을 측정하여, 라벨러들의 의견이 일치되지 않는 경우 라벨링 인스트럭션을 계속 개정하여 일관성이 생길때까지 개정해야한다.

![캡처3](.\acwa\캡처3.PNG)

4. 많은 벤치마킹 데이터셋을 다운받고 기계학습을 시키면 모델의 성능이 향상된다라고 익히 들어서 이러한 상황에 익숙해져 있는 우리. 모델 중심적 사고가 나쁜것은 아니다. 하지만 데이터 중심적 사고를 권한다. 그 이유는 ?

   ![캡처4](.\acwa\캡처4.PNG)

   - 모델 중심적 사고 : 데이터의 노이즈를 제거하여 모델을 향상 시킨다.
   - 데이터 중심적 사고 : 데이터의 일관성이 중요하다. 데이터 퀄리티를 향상시킬 수 있는 도구를 사용한다. 그러면 다수의 모델이 good working 하도록 만들 수 있다. 코드 수정은 잠깐 멈추고 데이터를 계속하여 향상시킬 수 있다.

5. 현대의 많은 모델은 low bias machine임, 일반적으로 분산문제이며, 데이터셋을 개선하는 것은 분산을 줄이는 좋은 방법이다.

6. 적은 데이터와 라벨 일관성

7. ![image-20211221174430800](.\acwa\캡처5)

clean and consistent small data를 가지고 (tools to make sure you have a clean and consistent data) 충분히 학습 알고리즘을 만들 수 있다!

8. 데이터 중심 관점에서 봤을 때, noise를 클린하는것과, 다른 500개의 새로운 example을 찾는 것(데이터셋을 두배로 하는 것)이 동등한 효과를 낳는것을 발견할 수 있다.

   ![image-20211221174859064](.\acwa\캡처6.png)

9. 데이터 클리닝 vs noisy data의 데이터 수 증가 비교했을때 데이터를 3배로 늘리는 것과 = data cleaning 동일한 효과를 낳는다.

   ![image-20211221175209458](.\acwa\캡처7.png)

10. 

