# MLflow Tracking

### ê° Running ì—ì„œ ê¸°ë¡ë˜ëŠ” ì •ë³´

![Untitled](MLflow%20Tracking/Untitled.png)

- Source : ëª¨ë¸ íŒŒì¼ ëª…
- Start Time & End Time : ì‹œì‘ ë° ì¢…ë£Œì‹œê°„
- Parameters (key -value êµ¬ì¡°)
- Metrics
- Artifacts (ëª¨ë¸ íŒŒì¼, ë°ì´í„° íŒŒì¼)

### [ ì˜ˆì‹œ : IMDB ì˜í™” ê°ì„± ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ]

# ì‹œë‚˜ë¦¬ì˜¤ 1 : localhostì—ì„œ Local File Systemì— Artifact ì €ì¥

### ì•„í‚¤í…ì²˜ ì´ë¯¸ì§€

![Untitled](MLflow%20Tracking/Untitled%201.png)

## Version 1 ) Local - manually

```python
import tensorflow
import os
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GRU, Embedding
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import mlflow

#ì´ë¯¸ í›ˆë ¨, í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ 50:50ë¡œ êµ¬ë¶„ë˜ì–´ ì œê³µë¨.
# ì˜í™” ë¦¬ë·°ëŠ” X_trainì—, ê°ì„± ì •ë³´ëŠ” y_trainì— ì €ì¥ëœë‹¤.
# í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·°ëŠ” X_testì—, í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·°ì˜ ê°ì„± ì •ë³´ëŠ” y_testì— ì €ì¥ëœë‹¤.
# (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)
# ìƒìœ„ 10000ê±´ì˜ ë‹¨ì–´ë“¤ë§Œ ì‚¬ìš©.

if __name__ == '__main__':
    **mlflow.set_experiment('classfication')**
    env = 'local'
    **mlflow.log_param('env', env)**

    print('1. Load Data')
    vocab_size = 10000
    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)

    print('í›ˆë ¨ìš© ë¦¬ë·° ê°œìˆ˜ : {}'.format(len(x_train)))
    print('í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·° ê°œìˆ˜ : {}'.format(len(x_test)))
    num_classes = max(y_train) + 1
    print('ì¹´í…Œê³ ë¦¬ : {}'.format(num_classes))
    
    print('2. Preprocessing')
    max_len = 500
    x_train = pad_sequences(x_train, maxlen=max_len)
    x_test = pad_sequences(x_test, maxlen=max_len)

    print('3. Build Model')
    model = Sequential()
    model.add(Embedding(vocab_size, 100))
    model.add(GRU(128))
    model.add(Dense(1, activation='sigmoid'))

    print('4. Model Train')
    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)
    mc = ModelCheckpoint('GRU_model.h5', monitor='val_acc', mode='max', verbose=1,save_best_only=True)

    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
    history = model.fit(x_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)

    print("\n í…ŒìŠ¤íŠ¸ ì •í™•ë„ : %.4f"%(model.evaluate(x_test, y_test)[1]))

    **mlflow.log_metric('accuracy', model.evaluate(x_test, y_test)[1])**

    # MLflow Tracking (parameter)
    import random
    random_no = random.randrange(0, len(x_train))

    **mlflow.log_param("train", 'from tensorflow.keras.datasets.imdb')
    mlflow.log_param("train num", len(x_train))
    mlflow.log_param("class num", num_classes)
    mlflow.log_param("class", {0:'negative', 1:'positive'})
    mlflow.log_param("train example", x_train[random_no])
    mlflow.log_param("train text max length", max([len(x) for x in x_train]))
    mlflow.log_param("train text average length", sum([len(x) for x in x_train])/len(x_train))

    mlflow.tensorflow.log_model(model, "model", pip_requirements=[f"tensorflow=={tensorflow.__version__}"])**
```

## Version 2 ) Local - Autolog

<aside>
ğŸ’¡ tf2ë„ ì ìš©í•œ ì½”ë“œê°€ ìˆë‹¤ë©´ í¬í•¨!

</aside>

```python
import os
import tensorflow
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GRU, Embedding
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import mlflow
from pprint import pprint
from mlflow.tracking.client import MlflowClient

#ì´ë¯¸ í›ˆë ¨, í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ 50:50ë¡œ êµ¬ë¶„ë˜ì–´ ì œê³µë¨.
# ì˜í™” ë¦¬ë·°ëŠ” X_trainì—, ê°ì„± ì •ë³´ëŠ” y_trainì— ì €ì¥ëœë‹¤.
# í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·°ëŠ” X_testì—, í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·°ì˜ ê°ì„± ì •ë³´ëŠ” y_testì— ì €ì¥ëœë‹¤.
# (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)
# ìƒìœ„ 10000ê±´ì˜ ë‹¨ì–´ë“¤ë§Œ ì‚¬ìš©.

def fetch_logged_data(run_id):
    client = MlflowClient()
    return client.get_run(run_id).to_dictionary()['data']

if __name__ == '__main__':
    **mlflow.tensorflow.autolog()**
    **mlflow.set_experiment('classfication-Autolog')**

    print('1. Load Data')
    vocab_size = 10000
    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)

    print('í›ˆë ¨ìš© ë¦¬ë·° ê°œìˆ˜ : {}'.format(len(x_train)))
    print('í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·° ê°œìˆ˜ : {}'.format(len(x_test)))
    num_classes = max(y_train) + 1
    print('ì¹´í…Œê³ ë¦¬ : {}'.format(num_classes))
    
    print('2. Preprocessing')
    max_len = 500
    x_train = pad_sequences(x_train, maxlen=max_len)
    x_test = pad_sequences(x_test, maxlen=max_len)

    if(mlflow.active_run):
        mlflow.end_run()

    **with mlflow.start_run() as run:**
        print('3. Build Model')
        model = Sequential()
        model.add(Embedding(vocab_size, 100))
        model.add(GRU(128))
        model.add(Dense(1, activation='sigmoid'))

        print('4. Model Train')
        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)
        mc = ModelCheckpoint('GRU_model.h5', monitor='val_acc', mode='max', verbose=1,save_best_only=True)

        print("Logged data and model in run {}".format(run.info.run_id))
        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
        history = model.fit(x_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)
        print("\n í…ŒìŠ¤íŠ¸ ì •í™•ë„ : %.4f"%(model.evaluate(x_test, y_test)[1]))

         # show logged data
        for key, data in fetch_logged_data(run.info.run_id).items():
            print("\n---------- logged {} - ---------".format(key))
            pprint(data)
```

# ì‹œë‚˜ë¦¬ì˜¤ 2 : Tracking Server DBì™€ Local File Systemì— Artifact ì €ì¥

### ì•„í‚¤í…ì²˜ ì´ë¯¸ì§€

![Untitled](MLflow%20Tracking/Untitled%202.png)

# ì‹œë‚˜ë¦¬ì˜¤ 3 : Tracking Server DBì™€ SFTPë¥¼ í†µí•œ Remote File Systemì— Artifact ì €ì¥

### ì•„í‚¤í…ì²˜ ì´ë¯¸ì§€

![Untitled](MLflow%20Tracking/Untitled%203.png)

## Version 1 ) Server - manually

<aside>
ğŸ’¡ MLflow í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰ì‹œí‚¤ê¸° ìœ„í•´ì„œ backend serverì™€ ì—°ê²°í•´ì£¼ëŠ” ì‘ì—…ì´ í•„ìš”í•˜ë‹¤. ì´ëŠ” ê°„ë‹¨í•˜ê²Œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆë‹¤.

```bash
$ export MLFLOW_TRACKING_URI="{ì„œë²„ì˜ URI}"
```

</aside>

```python
import tensorflow
import os
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GRU, Embedding
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import mlflow

#ì´ë¯¸ í›ˆë ¨, í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ 50:50ë¡œ êµ¬ë¶„ë˜ì–´ ì œê³µë¨.
# ì˜í™” ë¦¬ë·°ëŠ” X_trainì—, ê°ì„± ì •ë³´ëŠ” y_trainì— ì €ì¥ëœë‹¤.
# í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·°ëŠ” X_testì—, í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·°ì˜ ê°ì„± ì •ë³´ëŠ” y_testì— ì €ì¥ëœë‹¤.
# (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)
# ìƒìœ„ 10000ê±´ì˜ ë‹¨ì–´ë“¤ë§Œ ì‚¬ìš©.

**artifact_uri = 'sftp:///mlops@192.168.1.70/home/mlops/mlflow/mlruns' # í™˜ê²½ë³€ìˆ˜ë¡œ ì§€ì • ê°€ëŠ¥í•œì§€ í…ŒìŠ¤íŠ¸**

if __name__ == '__main__':
    # uncomment line below when you want to set manually server to track (if you set ENV you don't have to uncomment line below )
    # mlflow.set_tracking_uri({SERVER URI})
		experiment_name = '**classfication**'
    if(mlflow.get_experiment_by_name(experiment_name)):
        **mlflow.set_registry_uri(artifact_uri)**
    else:
        **mlflow.create_experiment(name=experiment_name, artifact_location=artifact_uri)**
    **mlflow.set_experiment(experiment_name=experiment_name)**
    env = ''
    if(os.environ['MLFLOW_TRACKING_URI']):
        env = os.environ['MLFLOW_TRACKING_URI']
    # elif({SERVER URI}):
    #     env = {SERVER URI}
    else:
        env = 'local'
    **mlflow.log_param('env', env)**

    print('1. Load Data')
    vocab_size = 10000
    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)

    print('í›ˆë ¨ìš© ë¦¬ë·° ê°œìˆ˜ : {}'.format(len(x_train)))
    print('í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·° ê°œìˆ˜ : {}'.format(len(x_test)))
    num_classes = max(y_train) + 1
    print('ì¹´í…Œê³ ë¦¬ : {}'.format(num_classes))
    
    print('2. Preprocessing')
    max_len = 500
    x_train = pad_sequences(x_train, maxlen=max_len)
    x_test = pad_sequences(x_test, maxlen=max_len)

    print('3. Build Model')
    model = Sequential()
    model.add(Embedding(vocab_size, 100))
    model.add(GRU(128))
    model.add(Dense(1, activation='sigmoid'))

    print('4. Model Train')
    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)
    mc = ModelCheckpoint('GRU_model.h5', monitor='val_acc', mode='max', verbose=1,save_best_only=True)

    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
    history = model.fit(x_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)

    print("\n í…ŒìŠ¤íŠ¸ ì •í™•ë„ : %.4f"%(model.evaluate(x_test, y_test)[1]))

    **mlflow.log_metric('accuracy', model.evaluate(x_test, y_test)[1])**

    # MLflow Tracking (parameter)
    import random
    random_no = random.randrange(0, len(x_train))

    **mlflow.log_param("train", 'from tensorflow.keras.datasets.imdb')
    mlflow.log_param("train num", len(x_train))
    mlflow.log_param("class num", num_classes)
    mlflow.log_param("class", {0:'negative', 1:'positive'})
    mlflow.log_param("train example", x_train[random_no])
    mlflow.log_param("train text max length", max([len(x) for x in x_train]))
    mlflow.log_param("train text average length", sum([len(x) for x in x_train])/len(x_train))

    mlflow.tensorflow.log_model(model, "model", pip_requirements=[f"tensorflow=={tensorflow.__version__}"])**
```

## Version 2 ) Server - Autolog

<aside>
ğŸ’¡ MLflow í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰ì‹œí‚¤ê¸° ìœ„í•´ì„œ backend serverì™€ ì—°ê²°í•´ì£¼ëŠ” ì‘ì—…ì´ í•„ìš”í•˜ë‹¤. ì´ëŠ” ê°„ë‹¨í•˜ê²Œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆë‹¤.

```bash
$ export MLFLOW_TRACKING_URI="{ì„œë²„ì˜ URI}"
```

</aside>

```python
import os
import tensorflow
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GRU, Embedding
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import mlflow
from pprint import pprint
from mlflow.tracking.client import MlflowClient

#ì´ë¯¸ í›ˆë ¨, í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ 50:50ë¡œ êµ¬ë¶„ë˜ì–´ ì œê³µë¨.
# ì˜í™” ë¦¬ë·°ëŠ” X_trainì—, ê°ì„± ì •ë³´ëŠ” y_trainì— ì €ì¥ëœë‹¤.
# í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·°ëŠ” X_testì—, í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·°ì˜ ê°ì„± ì •ë³´ëŠ” y_testì— ì €ì¥ëœë‹¤.
# (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = 10000)
# ìƒìœ„ 10000ê±´ì˜ ë‹¨ì–´ë“¤ë§Œ ì‚¬ìš©.

def fetch_logged_data(run_id):
     # uncomment line below when you want to set manually server to track (if you set ENV you don't have to uncomment line below )
    # client = MlflowClient({SERVER URI})
    client = MlflowClient()
    return client.get_run(run_id).to_dictionary()['data']

if __name__ == '__main__':
		**mlflow.tensorflow.autolog()**
    
		# uncomment line below when you want to set manually server to track (if you set ENV you don't have to uncomment line below )
    # mlflow.set_tracking_uri({SERVER URI})
		
		experiment_name = '**classfication-auto**'
    if(mlflow.get_experiment_by_name(experiment_name)):
        pass
    else:
        **mlflow.create_experiment(name=experiment_name)**
    **mlflow.set_experiment(experiment_name=experiment_name)**
    env = ''
    if(os.environ['MLFLOW_TRACKING_URI']):
        env = os.environ['MLFLOW_TRACKING_URI']
    # elif({SERVER URI}):
    #     env = {SERVER URI}
    else:
        env = 'local'
    **mlflow.log_param('env', env)**
    
    
****
    print('1. Load Data')
    vocab_size = 10000
    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)

    print('í›ˆë ¨ìš© ë¦¬ë·° ê°œìˆ˜ : {}'.format(len(x_train)))
    print('í…ŒìŠ¤íŠ¸ìš© ë¦¬ë·° ê°œìˆ˜ : {}'.format(len(x_test)))
    num_classes = max(y_train) + 1
    print('ì¹´í…Œê³ ë¦¬ : {}'.format(num_classes))
    
    print('2. Preprocessing')
    max_len = 500
    x_train = pad_sequences(x_train, maxlen=max_len)
    x_test = pad_sequences(x_test, maxlen=max_len)

    if(mlflow.active_run):
        mlflow.end_run()

    **with mlflow.start_run() as run:**
        print('3. Build Model')
        model = Sequential()
        model.add(Embedding(vocab_size, 100))
        model.add(GRU(128))
        model.add(Dense(1, activation='sigmoid'))

        print('4. Model Train')
        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)
        mc = ModelCheckpoint('GRU_model.h5', monitor='val_acc', mode='max', verbose=1,save_best_only=True)

        print("Logged data and model in run {}".format(run.info.run_id))
        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
        history = model.fit(x_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)
        print("\n í…ŒìŠ¤íŠ¸ ì •í™•ë„ : %.4f"%(model.evaluate(x_test, y_test)[1]))

         # show logged data
        for key, data in fetch_logged_data(run.info.run_id).items():
            print("\n---------- logged {} - ---------".format(key))
            pprint(data)
```

# Tracking Server

### **ì‹œë‚˜ë¦¬ì˜¤ 2 : Tracking Server êµ¬ì¶• (**ğŸ–±ï¸)

<aside>
ğŸ’¡ ì—¬ëŸ¬ëª…ì˜ ëª¨ë¸ëŸ¬ë“¤ì´ ëª¨ë¸ ê°œë°œì„ í•  ë•Œ ë¡œê·¸ë¥¼ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•  ì„œë²„ê°€ í•„ìš”í•˜ë‹¤. 
MLflowëŠ” Tracking ì—­í• ì„ ìœ„í•œ ì„œë²„ë¥¼ ì œê³µí•œë‹¤. ì´ë¥¼ Tracking Serverë¼ê³  í•œë‹¤. 
Localì—ì„œ ì‘ì—…í•  ë•ŒëŠ” `./mlruns` ì— ë°”ë¡œ ë¡œê·¸ì™€ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆë‹¤ë©´ ì´ì œëŠ” ë°±ì—”ë“œ ì„œë²„ë¥¼ í†µí•´ì„œ ì €ì¥í•  ìˆ˜ ìˆë‹¤.

</aside>

ì•„ë˜ì™€ ê°™ì€ ëª…ë ¹ì–´ë¥¼ í†µí•´ ê°„ë‹¨í•˜ê²Œ Tracking Serverë¥¼ ë„ìš¸ ìˆ˜ ìˆë‹¤.

```bash
$ mkdir tracking-server
$ cd tracking-server

$ mlflow server -h 0.0.0.0 --backend-store-uri sqlite:///mlflow.db --default-artifact-root $(pwd)/artifacts

```

ì—¬ê¸°ì„œ `--backend-store-uri` ì™€ `--default-artifact-root` ëŠ” ë°‘ì—ì„œ ë‹¤ì‹œ ìì„¸íˆ í™•ì¸í•´ë³´ë„ë¡ í•˜ì.

ì´ì œ ë‹¤ì‹œ MLflowì˜ í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰ì‹œì¼œë³´ì. 

(ìœ„ì˜ ì˜ˆì‹œ ì¤‘ server - blahblahë¥¼ ì‹¤í–‰ì‹œí‚¤ë©´ ë¨.) 
í”„ë¡œì íŠ¸ ì‹¤í–‰ í›„ì— ì•„ê¹Œ ìƒì„±í•œ `tracking-server` ë””ë ‰í† ë¦¬ë¡œ ê°€ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤.

```bash
.
â”œâ”€â”€ artifacts
â”‚Â Â  â”œâ”€â”€ 0
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ 2df9ce14a7ec4431904f6e8292c08d67
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ artifacts
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”œâ”€â”€ model
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”‚Â Â  â”œâ”€â”€ MLmodel
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”‚Â Â  â”œâ”€â”€ conda.yaml
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”‚Â Â  â”œâ”€â”€ requirements.txt
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”‚Â Â  â””â”€â”€ tfmodel
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”‚Â Â      â”œâ”€â”€ saved_model.pb
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”‚Â Â      â””â”€â”€ variables
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”‚Â Â          â”œâ”€â”€ variables.data-00000-of-00001
â”‚Â Â  â”‚Â Â  â”‚Â Â      â”‚Â Â          â””â”€â”€ variables.index
â”‚Â Â  â”‚Â Â  â”‚Â Â      â””â”€â”€ tensorboard_logs
â”‚Â Â  â”‚Â Â  â””â”€â”€Â Â        â””â”€â”€ events.out.tfevents.1644278684.RSN-DL
â””â”€â”€ mlflow.db
```

`artifacts` : Tracking serverë¥¼ ì‹¤í–‰ì‹œì¼°ì„ ë•Œ model íŒŒì¼, í•™ìŠµ dataset íŒŒì¼ ë“±ì´ ì €ì¥ë¨.

`mlflow.db` : sqlite DB

### ì‹œë‚˜ë¦¬ì˜¤ 3 : Tracking Server êµ¬ì¶• ë° íŠ¸ëŸ¬ë¸” ìŠˆíŒ… (ğŸ–±ï¸)

<aside>
ğŸ’¡ ì—¬ëŸ¬ëª…ì˜ ëª¨ë¸ëŸ¬ë“¤ì´ ëª¨ë¸ ê°œë°œì„ í•  ë•Œ ë¡œê·¸ë¥¼ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•  ì„œë²„ê°€ í•„ìš”í•˜ë‹¤. 
MLflowëŠ” Tracking ì—­í• ì„ ìœ„í•œ ì„œë²„ë¥¼ ì œê³µí•œë‹¤. ì´ë¥¼ Tracking Serverë¼ê³  í•œë‹¤. 
Localì—ì„œ ì‘ì—…í•  ë•ŒëŠ” `./mlruns` ì— ë°”ë¡œ ë¡œê·¸ì™€ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆë‹¤ë©´ ì´ì œëŠ” ë°±ì—”ë“œ ì„œë²„ë¥¼ í†µí•´ì„œ ì €ì¥í•  ìˆ˜ ìˆë‹¤.

</aside>

[Setup MLflow in Production](https://medium.com/@gyani91/setup-mlflow-in-production-d72aecde7fef)

## sftpë¡œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ê´€ë¦¬í•˜ëŠ” serverë¡œ ê°„ë‹¨í•˜ê²Œ êµ¬ì¶•í•˜ê¸°!

ëª…ë ¹ì–´ë¥¼ í†µí•´ Tracking Serverë¥¼ ë„ìš¸ ìˆ˜ ìˆì§€ë§Œ, ìì£¼ ì‚¬ìš©í•˜ëŠ” ëª…ë ¹ì–´ì´ë¯€ë¡œ serviceì— ë“±ë¡í•´ë‘ì.

```bash
mlflow server --backend-store-uri sqlite:///home/mlops/mlflow/mlflow.db --default-artifact-root sftp:///mlops@192.168.1.70:/home/mlops/mlflow/mlruns
```

1. ssh ì—°ë™ (ë¹„ë°€ë²ˆí˜¸ ì—†ì´ sftp ì ‘ì†í•  ìˆ˜ ìˆë„ë¡ í•¨)
2. ê³µê°œí‚¤ ë“±ë¡ /user/.sshëŠ” ë¬¼ë¡  /root/.ssh ì—ë„ ë“±ë¡í•´ì•¼í•¨. ë§Œì•½ tracking serverë¼ê³  í•´ë„ ê±°ê¸°ì„œ model codeê°€ ìˆë‹¤ë©´ ê·¸ í‚¤ë„ ë“±ë¡í•´ì¤˜ì•¼ í•¨. (ìê¸°ìì‹ ì´ë¼ê³ í•˜ì§€ë§Œ sftp í”„ë¡œí† ì½œì„ í†µí•´ì„œ ì ‘ì†í•´ì•¼í•˜ê¸°ë•Œë¬¸ì„ ì‹«ìœ¼ë©´ ì•Œì•„ì„œ ê·¸ ë””ë ‰í† ë¦¬ë¥¼ ì§€ì •í•˜ë˜ê°€!)
3. /root/.sshì— ë“±ë¡í•˜ëŠ” ì´ìœ ëŠ” dashboardì—ì„œ ëª¨ë¸ artifactsì— ì ‘ê·¼í•˜ê¸° ìœ„í•¨ì„
4. `sftp://` url parsingì´ ì•ˆëœë‹¤ë©´?
    - ìì„¸íˆ
      
        ì¼ë‹¨ì€ set_tracking_urië§Œ í• ê²Œì•„ë‹ˆë¼ registry_urië„ ì„¤ì •í•´ì¤˜ì•¼í•¨. í™˜ê²½ë³€ìˆ˜ì—ì„œ ì–´ë–»ê²Œ ë¶ˆëŸ¬ì˜¤ëŠ”ì§€ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í• ë“¯.
        
        artifact_uri = 'sftp://mlops@192.168.1.70:22/home/mlops/mlflow/mlrunsâ€™
        
        ì´ í˜•íƒœë¡œ ì¨ì•¼í•¨. í¬íŠ¸ë„ ì¨ì¤˜ì•¼í–ˆìŒã…ã…ã…ã…ã…ã…,,,,,,
        
        ì¼ë‹¨ ì„¤ì •ì—ì„œ ë¯¸í¡í–ˆë˜ ì ì€ ssh-keygen ì—ì„œ í—·ê°ˆë¦¬ëŠ” ì ì´ ë§ì•˜ìŒ. 
        
        (ë¦¬ëˆ…ìŠ¤ ê³„ì •ì˜ ê³µê°œí‚¤ ë“±ë¡ ë° ê°œì¸í‚¤ ë°œê¸‰, localì´ë¼ ë‹¹ì—°íˆ sshì¸ì¦ì—†ì´ sftp ì ‘ì† ê°€ëŠ¥í•œ ì¤„ì•Œì•˜ì§€ë§Œ ì‚¬ì‹¤ì€ ìš°íšŒí•´ì„œ ë“¤ì–´ì˜¤ë¯€ë¡œ ssh ì¸ì¦ì´ í•„ìš”í–ˆìŒ, home ë””ë ‰í† ë¦¬ì˜ `~` ê°€ ì¸ì‹ë˜ì§€ ì•ŠëŠ” ë¬¸ì œ, ë””ë ‰í† ë¦¬ì˜ ê¶Œí•œ ë¬¸ì œ ë“±. ì•„ì§ í•´ê²°ë˜ì§€ ì•Šì€ ë¬¸ì œëŠ” mlflow ui ëŒ€ì‹œë³´ë“œê°€ root ê¶Œí•œìœ¼ë¡œ sftp ì¸ì‹í•˜ëŠ”ì§€ mlops ê¶Œí•œìœ¼ë¡œ ì ‘ê·¼í•˜ëŠ”ì§€ ì¢€ë” íŒŒë´ì•¼í•¨)
        
        ê·¸ë¦¬ê³  amazon s3ë¥¼ ì‚¬ìš©í•˜ë¼ëŠ” ë‚´ìš©ì´ ëŒ€ë¶€ë¶„ì´ì—ˆìœ¼ë©°
        
        sftprepository ë¥¼ ì—°ë™í•˜ëŠ”ê²ƒì— ëŒ€í•œ ë‚´ìš©ì´ ì•„ì§ ê³µì‹ë¬¸ì„œì— ì—†ê³  ì •ë§ ê·¹ì†Œìˆ˜ì˜ ì‚¬ë¡€ë¿ì„.
        
        ê²¨ìš° githubì—ì„œ ì†ŒìŠ¤ ê²€ìƒ‰í•´ì„œ ì°¾ì•„ì„œ ì—°ë™í–ˆë„¤ ê³ ë§™ë„¤ ì§€êµ¬ì´Œì´ì—¬